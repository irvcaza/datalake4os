# Archivo docker-compose para definir un stack de contenedores para un lago de datos 
# Creado por: Abel coronado https://github.com/abxda/datalake4os
# Modifcado por: Irving cabrera https://github.com/irvcaza/datalake4os

version: "3"

services:
######### Capa de data storage #########
# Nota: Este servicio no tiene ningun volumen asociado por lo que los datos quese carguen se destruiran al destruir el contenedor
#   , se recomienda crear un volumen
  minio:
    container_name: minio
    image: minio/minio:RELEASE.2020-04-10T03-34-42Z
    ports:
      - 9000:9000
    environment:
      MINIO_ACCESS_KEY: minio
      MINIO_SECRET_KEY: minio123
    command: server /data


######### Capa de data virtualization #########

  database:
    container_name: hive-database
    image: postgres:12
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive

  hive-server:
    container_name: hive-server
    ports: 
      - 10002:10002
    image: hive:3.1.0
    build:
      context: services/hive
      dockerfile: hive.dockerfile
    env_file:
      - ./services/hive/hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      HIVE_SITE_CONF_hive_metastore_uris: "thrift://hive-metastore:9083"
      # https://stackoverflow.com/a/53336873
      HIVE_SITE_CONF_hive_server2_active_passive_ha_enable: "true"
    depends_on: 
      - hive-metastore

  hive-metastore:
    container_name: hive-metastore
    image: hive:3.1.0
    build:
      context: services/hive
      dockerfile: hive.dockerfile
    volumes:
      - "./services/hivemetastore/create-table.hql:/tmp/create-table.hql"
    env_file:
      - ./services/hive/hive.env
    command: hivemetastore
    depends_on: 
      - database

  trino:
    container_name: trino
    image: trinodb/trino:354
    ports:
      - 8080:8080
    volumes:
      - "./services/trino/config.properties:/etc/trino/config.properties"
      - "./services/trino/hive.properties:/etc/trino/catalog/hive.properties"
  
######## Provision inicial de datos: 
## Crea los buckets necesarios para hive metastores por lo que crea la informacion y muere 
# Una vez que se crearon los buquets no es necesaria de nuevo 

#   create `hive` and `default` buckets
#   upload test data to minio
  mc:
    container_name: mc-provision
    image: minio/mc:RELEASE.2020-04-25T00-43-23Z
    entrypoint: >
      /bin/sh -c "
      sleep 5 && \
        mc config host add super-puper-config http://minio:9000 minio minio123 && \
        mc mb super-puper-config/hive && \
        mc mb super-puper-config/default && \
        mc cp /tmp/iris.csv super-puper-config/hive/warehouse/iris/iris.csv || exit 1;"
    volumes:
      - "./services/minio/dummy-data/iris.csv:/tmp/iris.csv"
    depends_on: 
      - "minio"

##################### Python para interactuar con los servicios 

## Archivo docker compose para lanzar contenedor de python con Jupyter Notebook

# Version docker compose.

  jupyter:
    build: ./services/python-jupyter # Utilizar imagen definida en Dockerfile con librerias extra definidas por el usuario 
    ports:
      - "8888:8888" # El puerto 8888 es por defecto en jupyter, se peude cambiar por otro para evitar colisiones 
    volumes:
      - ./services/python-jupyter/scripts:/home/jovyan/scripts # Monta la carpecta de scripts y notebooks
      - ./services/python-jupyter/data:/home/jovyan/data #  Monta la carpecta de datos 
    command: "start.sh jupyter lab --LabApp.token='password'" # Comando con el que arranca el notebook. Permite a√±adir variables a la ejecucion del notebook. '--LabApp.token' establece el token inicial para acceder al notebook

#### Los siguientes contenedores seran implementados en furutas iteraciones 
#   atlas:  
#     image: wbaa/rokku-dev-apache-atlas:0.1.5
#       container_name: atlas
#       ports:
#         - 21000:21000
#       networks:
#         - datalake4os-net
#     environment:
#         - ATLAS_KICKSTART_AMUNDSEN=true

#   amundsensearch:
#     build:
#       context: ./services/amundsensearchlibrary
#       dockerfile: public.Dockerfile
#     container_name: amundsensearch
#     ports:
#       - 5001:5001
#     environment:
#       - CREDENTIALS_PROXY_USER=admin
#       - CREDENTIALS_PROXY_PASSWORD=admin
#       - PROXY_ENDPOINT=http://atlas:21000
#       - PROXY_CLIENT=ATLAS
#     networks:
#       - datalake4os-net

#   amundsenmetadata:
#     build:
#       context: ./services/amundsenmetadatalibrary
#       dockerfile: public.Dockerfile
#     container_name: amundsenmetadata
#     ports:
#       - 5002:5002
#     networks:
#       - datalake4os-net      
#     environment:
#       - CREDENTIALS_PROXY_USER=admin
#       - CREDENTIALS_PROXY_PASSWORD=admin
#       - PROXY_HOST=http://atlas
#       - PROXY_PORT=21000
#       - PROXY_CLIENT=ATLAS

#   amundsenfrontend:
#     build:
#       context: ./services/amundsenfrontendlibrary
#       args:
#         SEARCHSERVICE_BASE: http://amundsensearch:5001
#         METADATASERVICE_BASE: http://amundsenmetadata:5002
#       dockerfile: local.Dockerfile
#     container_name: amundsenfrontend
#     depends_on:
#       - amundsenmetadata
#       - amundsensearch
#     ports:
#       - 5000:5000
#     networks:
#       - datalake4os-net   
#     environment:
#       - METADATASERVICE_BASE=http://amundsenmetadata:5002
#       - SEARCHSERVICE_BASE=http://amundsensearch:5001

networks:
  default:
    driver: bridge
    name: datalake4os-net
